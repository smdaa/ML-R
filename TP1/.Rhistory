glm.outAIC    = glm(formula(glm.outAIC),    datapp, family=binomial)
glm.outBIC    = glm(formula(glm.outBIC),    datapp, family=binomial)
glm.outintAIC = glm(formula(glm.outintAIC), datapp, family=binomial)
glm.outintBIC = glm(formula(glm.outintBIC), datapp, family=binomial)
a.aic  = c(a.aic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outAIC))$bs)
a.bic  = c(a.bic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outBIC))$bs)
a.aint = c(a.aint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintAIC))$bs)
a.bint = c(a.bint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintBIC))$bs)
t.aic  = c(t.aic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outAIC,    datatest, type="response")>0.2)$bs)
t.bic  = c(t.bic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outBIC,    datatest, type="response")>0.2)$bs)
t.aint = c(t.aint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintAIC, datatest, type="response")>0.2)$bs)
t.bint = c(t.bint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintBIC, datatest, type="response")>0.2)$bs)
}
X11()
boxplot(a.bic, a.aic, a.bint, a.aint, t.bic, t.aic, t.bint, t.aint,
col   = c("blue", "blue", "blue", "blue", "red", "red", "red", "red"),
names = c("a.bic", "a.aic", "a.bint", "a.aint", "t.bic", "t.aic", "t.bint", "t.aint"),
main  = "Regression logistique Brier Score")
set.seed(10)
data_shuffle = data[sample(nrow(data)),]
K     = 20
folds = cut(seq(1,nrow(data)), breaks=K, labels=FALSE)
# brier score
a.aic  = c()
a.bic  = c()
a.aint = c()
a.bint = c()
t.aic  = c()
t.bic  = c()
t.aint = c()
t.bint = c()
for(i in 1:K){
index_test  = which(folds==i, arr.ind=TRUE)
datatest    = data[index_test,]
datapp      = data[-index_test, ]
glm.outAIC    = glm(formula(glm.outAIC),    datapp, family=binomial)
glm.outBIC    = glm(formula(glm.outBIC),    datapp, family=binomial)
glm.outintAIC = glm(formula(glm.outintAIC), datapp, family=binomial)
glm.outintBIC = glm(formula(glm.outintBIC), datapp, family=binomial)
a.aic  = c(a.aic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outAIC))$bs)
a.bic  = c(a.bic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outBIC))$bs)
a.aint = c(a.aint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintAIC))$bs)
a.bint = c(a.bint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintBIC))$bs)
t.aic  = c(t.aic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outAIC,    datatest, type="response")>0.2)$bs)
t.bic  = c(t.bic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outBIC,    datatest, type="response")>0.2)$bs)
t.aint = c(t.aint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintAIC, datatest, type="response")>0.2)$bs)
t.bint = c(t.bint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintBIC, datatest, type="response")>0.2)$bs)
}
X11()
boxplot(a.bic, a.aic, a.bint, a.aint, t.bic, t.aic, t.bint, t.aint,
col   = c("blue", "blue", "blue", "blue", "red", "red", "red", "red"),
names = c("a.bic", "a.aic", "a.bint", "a.aint", "t.bic", "t.aic", "t.bint", "t.aint"),
main  = "Regression logistique Brier Score")
set.seed(10)
data_shuffle = data[sample(nrow(data)),]
K     = 10
folds = cut(seq(1,nrow(data)), breaks=K, labels=FALSE)
# brier score
a.aic  = c()
a.bic  = c()
a.aint = c()
a.bint = c()
t.aic  = c()
t.bic  = c()
t.aint = c()
t.bint = c()
for(i in 1:K){
index_test  = which(folds==i, arr.ind=TRUE)
datatest    = data[index_test,]
datapp      = data[-index_test, ]
glm.outAIC    = glm(formula(glm.outAIC),    datapp, family=binomial)
glm.outBIC    = glm(formula(glm.outBIC),    datapp, family=binomial)
glm.outintAIC = glm(formula(glm.outintAIC), datapp, family=binomial)
glm.outintBIC = glm(formula(glm.outintBIC), datapp, family=binomial)
a.aic  = c(a.aic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outAIC))$bs)
a.bic  = c(a.bic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outBIC))$bs)
a.aint = c(a.aint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintAIC))$bs)
a.bint = c(a.bint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintBIC))$bs)
t.aic  = c(t.aic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outAIC,    datatest, type="response")>0.2)$bs)
t.bic  = c(t.bic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outBIC,    datatest, type="response")>0.2)$bs)
t.aint = c(t.aint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintAIC, datatest, type="response")>0.2)$bs)
t.bint = c(t.bint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintBIC, datatest, type="response")>0.2)$bs)
}
X11()
boxplot(a.bic, a.aic, a.bint, a.aint, t.bic, t.aic, t.bint, t.aint,
col   = c("blue", "blue", "blue", "blue", "red", "red", "red", "red"),
names = c("a.bic", "a.aic", "a.bint", "a.aint", "t.bic", "t.aic", "t.bint", "t.aint"),
main  = "Regression logistique Brier Score")
set.seed(10)
data_shuffle = data[sample(nrow(data)),]
K     = 10
folds = cut(seq(1,nrow(data)), breaks=K, labels=FALSE)
# brier score
a.aic  = c()
a.bic  = c()
a.aint = c()
a.bint = c()
t.aic  = c()
t.bic  = c()
t.aint = c()
t.bint = c()
for(i in 1:K){
index_test  = which(folds==i, arr.ind=TRUE)
datatest    = data_shuffle[index_test,]
datapp      = data_shuffle[-index_test, ]
glm.outAIC    = glm(formula(glm.outAIC),    datapp, family=binomial)
glm.outBIC    = glm(formula(glm.outBIC),    datapp, family=binomial)
glm.outintAIC = glm(formula(glm.outintAIC), datapp, family=binomial)
glm.outintBIC = glm(formula(glm.outintBIC), datapp, family=binomial)
a.aic  = c(a.aic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outAIC))$bs)
a.bic  = c(a.bic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outBIC))$bs)
a.aint = c(a.aint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintAIC))$bs)
a.bint = c(a.bint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintBIC))$bs)
t.aic  = c(t.aic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outAIC,    datatest, type="response")>0.2)$bs)
t.bic  = c(t.bic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outBIC,    datatest, type="response")>0.2)$bs)
t.aint = c(t.aint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintAIC, datatest, type="response")>0.2)$bs)
t.bint = c(t.bint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintBIC, datatest, type="response")>0.2)$bs)
}
X11()
boxplot(a.bic, a.aic, a.bint, a.aint, t.bic, t.aic, t.bint, t.aint,
col   = c("blue", "blue", "blue", "blue", "red", "red", "red", "red"),
names = c("a.bic", "a.aic", "a.bint", "a.aint", "t.bic", "t.aic", "t.bint", "t.aint"),
main  = "Regression logistique Brier Score")
set.seed(10)
data_shuffle = data[sample(nrow(data)),]
K     = 5
folds = cut(seq(1,nrow(data)), breaks=K, labels=FALSE)
# brier score
a.aic  = c()
a.bic  = c()
a.aint = c()
a.bint = c()
t.aic  = c()
t.bic  = c()
t.aint = c()
t.bint = c()
for(i in 1:K){
index_test  = which(folds==i, arr.ind=TRUE)
datatest    = data_shuffle[index_test,]
datapp      = data_shuffle[-index_test, ]
glm.outAIC    = glm(formula(glm.outAIC),    datapp, family=binomial)
glm.outBIC    = glm(formula(glm.outBIC),    datapp, family=binomial)
glm.outintAIC = glm(formula(glm.outintAIC), datapp, family=binomial)
glm.outintBIC = glm(formula(glm.outintBIC), datapp, family=binomial)
a.aic  = c(a.aic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outAIC))$bs)
a.bic  = c(a.bic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outBIC))$bs)
a.aint = c(a.aint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintAIC))$bs)
a.bint = c(a.bint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintBIC))$bs)
t.aic  = c(t.aic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outAIC,    datatest, type="response")>0.2)$bs)
t.bic  = c(t.bic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outBIC,    datatest, type="response")>0.2)$bs)
t.aint = c(t.aint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintAIC, datatest, type="response")>0.2)$bs)
t.bint = c(t.bint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintBIC, datatest, type="response")>0.2)$bs)
}
X11()
boxplot(a.bic, a.aic, a.bint, a.aint, t.bic, t.aic, t.bint, t.aint,
col   = c("blue", "blue", "blue", "blue", "red", "red", "red", "red"),
names = c("a.bic", "a.aic", "a.bint", "a.aint", "t.bic", "t.aic", "t.bint", "t.aint"),
main  = "Regression logistique Brier Score")
set.seed(666)
data_shuffle = data[sample(nrow(data)),]
K     = 20
folds = cut(seq(1,nrow(data)), breaks=K, labels=FALSE)
# brier score
a.aic  = c()
a.bic  = c()
a.aint = c()
a.bint = c()
t.aic  = c()
t.bic  = c()
t.aint = c()
t.bint = c()
for(i in 1:K){
index_test  = which(folds==i, arr.ind=TRUE)
datatest    = data_shuffle[index_test,]
datapp      = data_shuffle[-index_test, ]
glm.outAIC    = glm(formula(glm.outAIC),    datapp, family=binomial)
glm.outBIC    = glm(formula(glm.outBIC),    datapp, family=binomial)
glm.outintAIC = glm(formula(glm.outintAIC), datapp, family=binomial)
glm.outintBIC = glm(formula(glm.outintBIC), datapp, family=binomial)
a.aic  = c(a.aic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outAIC))$bs)
a.bic  = c(a.bic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outBIC))$bs)
a.aint = c(a.aint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintAIC))$bs)
a.bint = c(a.bint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintBIC))$bs)
t.aic  = c(t.aic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outAIC,    datatest, type="response")>0.2)$bs)
t.bic  = c(t.bic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outBIC,    datatest, type="response")>0.2)$bs)
t.aint = c(t.aint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintAIC, datatest, type="response")>0.2)$bs)
t.bint = c(t.bint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintBIC, datatest, type="response")>0.2)$bs)
}
X11()
boxplot(a.bic, a.aic, a.bint, a.aint, t.bic, t.aic, t.bint, t.aint,
col   = c("blue", "blue", "blue", "blue", "red", "red", "red", "red"),
names = c("a.bic", "a.aic", "a.bint", "a.aint", "t.bic", "t.aic", "t.bint", "t.aint"),
main  = "Regression logistique Brier Score")
set.seed(666)
data_shuffle = data[sample(nrow(data)),]
K     = 3
folds = cut(seq(1,nrow(data)), breaks=K, labels=FALSE)
# brier score
a.aic  = c()
a.bic  = c()
a.aint = c()
a.bint = c()
t.aic  = c()
t.bic  = c()
t.aint = c()
t.bint = c()
for(i in 1:K){
index_test  = which(folds==i, arr.ind=TRUE)
datatest    = data_shuffle[index_test,]
datapp      = data_shuffle[-index_test, ]
glm.outAIC    = glm(formula(glm.outAIC),    datapp, family=binomial)
glm.outBIC    = glm(formula(glm.outBIC),    datapp, family=binomial)
glm.outintAIC = glm(formula(glm.outintAIC), datapp, family=binomial)
glm.outintBIC = glm(formula(glm.outintBIC), datapp, family=binomial)
a.aic  = c(a.aic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outAIC))$bs)
a.bic  = c(a.bic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outBIC))$bs)
a.aint = c(a.aint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintAIC))$bs)
a.bint = c(a.bint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintBIC))$bs)
t.aic  = c(t.aic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outAIC,    datatest, type="response")>0.2)$bs)
t.bic  = c(t.bic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outBIC,    datatest, type="response")>0.2)$bs)
t.aint = c(t.aint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintAIC, datatest, type="response")>0.2)$bs)
t.bint = c(t.bint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintBIC, datatest, type="response")>0.2)$bs)
}
X11()
boxplot(a.bic, a.aic, a.bint, a.aint, t.bic, t.aic, t.bint, t.aint,
col   = c("blue", "blue", "blue", "blue", "red", "red", "red", "red"),
names = c("a.bic", "a.aic", "a.bint", "a.aint", "t.bic", "t.aic", "t.bint", "t.aint"),
main  = "Regression logistique Brier Score")
set.seed(666)
data_shuffle = data[sample(nrow(data)),]
K     = 10
folds = cut(seq(1,nrow(data)), breaks=K, labels=FALSE)
# brier score
a.aic  = c()
a.bic  = c()
a.aint = c()
a.bint = c()
t.aic  = c()
t.bic  = c()
t.aint = c()
t.bint = c()
for(i in 1:K){
index_test  = which(folds==i, arr.ind=TRUE)
datatest    = data_shuffle[index_test,]
datapp      = data_shuffle[-index_test, ]
glm.outAIC    = glm(formula(glm.outAIC),    datapp, family=binomial)
glm.outBIC    = glm(formula(glm.outBIC),    datapp, family=binomial)
glm.outintAIC = glm(formula(glm.outintAIC), datapp, family=binomial)
glm.outintBIC = glm(formula(glm.outintBIC), datapp, family=binomial)
a.aic  = c(a.aic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outAIC))$bs)
a.bic  = c(a.bic,  brier(as.numeric(datapp$OCC)-1, fitted(glm.outBIC))$bs)
a.aint = c(a.aint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintAIC))$bs)
a.bint = c(a.bint, brier(as.numeric(datapp$OCC)-1, fitted(glm.outintBIC))$bs)
t.aic  = c(t.aic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outAIC,    datatest, type="response")>0.2)$bs)
t.bic  = c(t.bic, brier(as.numeric(datatest$OCC)-1,  predict(glm.outBIC,    datatest, type="response")>0.2)$bs)
t.aint = c(t.aint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintAIC, datatest, type="response")>0.2)$bs)
t.bint = c(t.bint, brier(as.numeric(datatest$OCC)-1, predict(glm.outintBIC, datatest, type="response")>0.2)$bs)
}
X11()
boxplot(a.bic, a.aic, a.bint, a.aint, t.bic, t.aic, t.bint, t.aint,
col   = c("blue", "blue", "blue", "blue", "red", "red", "red", "red"),
names = c("a.bic", "a.aic", "a.bint", "a.aint", "t.bic", "t.aic", "t.bint", "t.aint"),
main  = "Regression logistique Brier Score")
########################
#         AD           #
########################
iOCC  = which(data$OCC==1)
iNOCC = which(data$OCC==0)
var.test(data$FFp[iOCC],data$FFp[iNOCC])          # not equal
var.test(data$HU[iOCC],data$HU[iNOCC])            # not equal
var.test(data$P[iOCC],data$P[iNOCC])              # not equal
var.test(data$u[iOCC],data$u[iNOCC])              # not equal
var.test(data$v[iOCC],data$v[iNOCC])              # not equal
var.test(data$hel[iOCC],data$hel[iNOCC])          # not equal
var(data[iOCC,-c(11,12,13)]) - var(data[iNOCC,-c(11,12,13)])
cor(data[iOCC,-c(11,12,13)]) - cor(data[iNOCC,-c(11,12,13)])
lda.out=lda(OCC~.,data[,-11])
X11()
roc.plot(as.numeric(data$OCC)-1,predict(lda.out)$posterior[,2])
qda.out=qda(OCC~.,datapp[,-11])
X11()
roc.plot(as.numeric(data$OCC)-1,predict(lda.out)$posterior[,2])
###############
#     MLG     #
###############
library(MASS)
data = read.table('DataTP.txt', header = TRUE)
lm.out    = lm(FFo~., data)
lm.outint = lm(FFo~.*.,data)
# Residuals analysis
X11()
par(mfrow=c(2, 2))
plot(fitted(lm.out), residuals(lm.out),
main = "Hypothese d'homoscedasticite", xlab="fitted values",
ylab = "residuals")
qqnorm(residuals(lm.out)) # we can see that the majority of the theoritical quantiles and the sample quantiles
# match up. this test helps to verify the hypothesis that the residuals follow the normal distribution.
hist(residuals(lm.out)) # same as before we plot the distribution of the residuals to compare it to a normal distribution.
acf(residuals(lm.out)) # this test is to verify that the residuals are independant which is the case because we see a fall off
# in the Acf after the third lag.
summary(lm.out) # we can keep HU P v heure FFp as predictors since they have a p-value below 0.05 so their impact on FFo
# cant be ignored.
# AIC
lm.outAIC    = stepAIC(lm.out)
lm.outintAIC = stepAIC(lm.outint)
# BIC
lm.outBIC    = stepAIC(lm.out,    k=log(nrow(data)))
lm.outintBIC = stepAIC(lm.outint, k=log(nrow(data)))
nappr = ceiling(0.8*nrow(data))
ii    = sample(1:nrow(data),nappr)
jj    = setdiff(1:nrow(data),ii)
datatest = data[jj,]
datapp   = data[ii,]
# RMSE
RMSE = function(obs,pr){
return(sqrt(mean((pr-obs)^2)))
}
RMSE(datapp$FFo, fitted(lm.outAIC))
RMSE(datatest$FFo, predict(lm.outAIC, datatest))
RMSE(datapp$FFo, fitted(lm.outAIC))
fitted(lm.outAIC)
nrow(fitted(lm.outAIC))
lm.out    = lm(FFo~., data)
lm.outint = lm(FFo~.*.,data)
lm.outAIC    = lm(formula(lm.outAIC), datapp)
lm.outintAIC = lm(formula(lm.outintAIC), datapp)
RMSE(datapp$FFo, fitted(lm.outAIC))
RMSE(datatest$FFo, predict(lm.outAIC, datatest))
library(MASS)
library(verification)
data = read.table('DataTP.txt', header = TRUE)
data$OCC = as.factor(as.numeric(data$FFo>13))
data$OCCp = as.factor(as.numeric(data$FFp>13))
glm.out    = glm(OCC~., data[,-11], family=binomial)
glm.outAIC = stepAIC(glm.out)
X11()
roc.plot(as.numeric(data$OCC)-1,fitted(glm.outAIC))
scores(fitted(glm.outAIC)>0.2, data$OCC)
source("scores.R")
scores(fitted(glm.outAIC)>0.2, data$OCC)
nappr=ceiling(0.8*nrow(data))
ii=sample(1:nrow(data),nappr)
jj=setdiff(1:nrow(data),ii)
datatest=data[jj,]
datapp=data[ii,]
glm.outAIC = glm(formula(glm.outAIC), datapp, family=binomial)
fitted(glm.outAIC)
as.numeric(datatest$OCC)-1
predict(glm.outAIC, datatest, type="response")>0.2
fitted(glm.outAIC)
predict(glm.outAIC, datatest, type="response")
glm.outAIC = glm(formula(glm.outAIC), datapp, family=binomial)
scores(fitted(glm.outAIC)>0.2, datapp$OCC)
brier(as.numeric(datapp$OCC)-1, fitted(glm.outAIC))$bs
scores(predict(glm.outAIC, datatest, type="response")>0.2, datatest$OCC)
brier(as.numeric(datatest$OCC)-1, predict(glm.outAIC, datatest, type="response"))$bs
roc.area(as.numeric(datapp$OCC)-1, predict(glm.outAIC, datatest, type="response"))$A
###############
#     AD     #
###############
lda.out=lda(OCC~.,data[,-11])
qda.out=qda(OCC~.,data[,-11])
summary(lda)
summary(lda.out)
X11()
roc.plot(as.numeric(data$OCC)-1, predict(lda.out)$posterior[,2])
scores(predict(lda.out)$posterior[,2]>0.2, datapp$OCC)
lda.out=lda(OCC~.,datapp[,-11])
qda.out=qda(OCC~.,datapp[,-11])
scores(predict(lda.out)$posterior[,2]>0.2, datapp$OCC)
brier(as.numeric(datapp$OCC)-1,   predict(lda.out)$posterior[,2])$bs
roc.area(as.numeric(datapp$OCC)-1, predict(lda.out)$posterior[,2])$A
scores(predict(lda.out, datatest)$posterior[,2]>0.2, datatest$OCC)
roc.area(as.numeric(datatest$OCC)-1, predict(lda.out, datatest)$posterior[,2])$A
nappr=ceiling(0.8*nrow(data))
ii=sample(1:nrow(data),nappr)
jj=setdiff(1:nrow(data),ii)
datatest=data[jj,]
datapp=data[ii,]
gamreg.out = gam(FFo~lo(heure)+lo(v)+lo(FFp),family=gaussian,datapp)
library(verification)
library(gam)
library(akima)
gamreg.out = gam(FFo~lo(heure)+lo(v)+lo(FFp),family=gaussian,datapp)
RMSE(datatest$FFo, predict(gam.out,datatest))
library(MASS)
data = read.table('DataTP.txt', header = TRUE)
lm.out = lm(FFo~., data)
X11()
par(mfrow=c(2, 2))
plot(fitted(lm.out), residuals(lm.out),
main = "Hypothese d'homoscedasticite", xlab="fitted values",
ylab = "residuals")
qqnorm(residuals(lm.out)) # we can see that the majority of the theoritical quantiles and the sample quantiles
# match up. this test helps to verify the hypothesis that the residuals follow the normal distribution.
hist(residuals(lm.out)) # same as before we plot the distribution of the residuals to compare it to a normal distribution.
acf(residuals(lm.out)) # this test is to verify that the residuals are independant which is the case because we see a fall off
# in the Acf after the third lag.
summary(lm.out) # we can keep HU P v heure FFp as predictors since they have a p-value below 0.05 so their impact on FFo
# cant be ignored.
lm.outint=lm(FFo~.*.,data)
X11()
par(mfrow=c(2,2))
plot(fitted(lm.outint),residuals(lm.outint),main="Hypothese d'homoscedasticite",xlab="Valeurs ajustees (Y*)",ylab="Residus")
hist(residuals(lm.outint))
qqnorm(residuals(lm.outint))
acf(residuals(lm.outint))
summary(lm.outint)
Bias.out = mean(data$FFo - fitted(lm.out))
RMSE.out = sqrt(mean((data$FFo - fitted(lm.out))**2))
Bias.outint = mean(data$FFo - fitted(lm.outint))
RMSE.outint = sqrt(mean((data$FFo - fitted(lm.outint))**2))
cat("Bias of lm.out :", Bias.out, "\n")
cat("Bias of lm.outint  :", Bias.outint, "\n")
cat("RMSE of lm.out :", RMSE.out, "\n")
cat("RMSE of lm.outint  :", RMSE.outint, "\n")
lm.outAIC    = stepAIC(lm.out)
lm.outintAIC = stepAIC(lm.outint)
lm.outBIC    = stepAIC(lm.out, k=log(nrow(data)))
lm.outintBIC = stepAIC(lm.outint, k=log(nrow(data)))
eval=function(obs, prev) {
rmse  = sqrt(mean((prev - obs)**2))
biais = mean(prev - obs)
return(c(biais,rmse))
}
# we can see that in our simple test the int models outperform the simple models on the train data and the test data.
# K-fold cross validation
set.seed(10)
K = 10
rows = sample(nrow(data))
datashuffle = data[rows,]
ntest = ceiling((1/K) * nrow(data))
endtest = 0
a.aic = c()
a.bic = c()
a.aint = c()
a.bint = c()
a.INT = c()
t.aic = c()
t.bic = c()
t.aint = c()
t.bint = c()
t.INT = c()
for (i in 1:K) {
starttest = endtest + 1
endtest   = i * ntest
if (endtest > nrow(data)) {
endtest = nrow(data)
}
datatest = datashuffle[starttest:endtest,]
datapp   = datashuffle[setdiff(1:nrow(data), starttest:endtest),]
lm.outAIC = lm(formula(lm.outAIC), datapp)
lm.outBIC = lm(formula(lm.outBIC), datapp)
lm.outintAIC = lm(formula(lm.outintAIC), datapp)
lm.outintBIC = lm(formula(lm.outintBIC), datapp)
lm.INT = lm(FFo~.*.*. ,datapp)
t.aic = c(t.aic, eval(datatest$FFo, predict(lm.outAIC, datatest))[2])
t.bic = c(t.bic, eval(datatest$FFo, predict(lm.outBIC, datatest))[2])
t.aint = c(t.aint, eval(datatest$FFo, predict(lm.outintAIC, datatest))[2])
t.bint = c(t.bint, eval(datatest$FFo, predict(lm.outintBIC, datatest))[2])
t.INT  = c(t.INT, eval(datatest$FFo, predict(lm.INT, datatest))[2])
a.aic = c(a.aic, eval(datapp$FFo, fitted(lm.outAIC))[2])
a.bic = c(a.bic, eval(datapp$FFo, fitted(lm.outBIC))[2])
a.aint = c(a.aint, eval(datapp$FFo, fitted(lm.outintAIC))[2])
a.bint = c(a.bint, eval(datapp$FFo, fitted(lm.outintBIC))[2])
a.INT  = c(a.INT, eval(datapp$FFo, fitted(lm.INT))[2])
}
X11()
boxplot(a.bic, a.aic, a.bint, a.aint, a.INT, t.bic, t.aic, t.bint, t.aint, t.INT,
col   = c("blue", "blue", "blue", "blue", "blue", "red", "red", "red", "red", "red"),
names = c("a.bic", "a.aic", "a.bint", "a.aint", "a.INT", "t.bic", "t.aic", "t.bint", "t.aint", "t.INT"),
main  = "Modele lineaire gaussien - Score RMSE")
X11()
plot(data$FFo[300:400], type ="l", main="Force de vent",xlab="Date",ylab="[FFo]")
points(data$FFp[300:400], col="blue", pch="+")
points(fitted(lm.outintBIC)[300:400], col="red", pch="+")
legend(0, 25, lty=1, col=c("black"), legend=c("FFo"), bty="n")
legend(0, 23, pch="+", col="blue", legend="FFp", bty="n")
legend(0, 21, pch="+", col="red", legend="régression intbic", bty="n")
library(MASS)
library(verification)
data = read.table('DataTP.txt', header = TRUE)
data$OCC = as.factor(as.numeric(data$FFo>13))
data$OCCp = as.factor(as.numeric(data$FFp>13))
source("scores.R")
glm.out    = glm(OCC~., data[,-11], family=binomial)    # we remove FFo from the dataset because duh
glm.outint = glm(OCC~.*.,data[,-11],family=binomial)
glm.outAIC = stepAIC(glm.out)
glm.outBIC = stepAIC(glm.out,k=log(nrow(data)))
glm.outintAIC = stepAIC(glm.outint)
glm.outintBIC = stepAIC(glm.outint,k=log(nrow(data)))
formula(glm.outAIC)
formula(glm.outBIC)
formula(glm.outintAIC)
formula(glm.outintBIC)
library("gam")
library("akima")
library("verification")
data=read.table("DataTP.txt",header=TRUE)
source("scores.R")
eval=function(obs,prev) {
rmse=sqrt(mean((prev-obs)**2))
biais=mean(prev-obs)
return(c(biais,rmse))
}
gamreg.out = gam(FFo~ lo(heure)+lo(v)+lo(u)+lo(FFp)+lo(HU)+lo(N)+lo(P)+lo(hel)+lo(DD)+lo(mois), data, family=gaussian)
summary(gamreg.out)
eval(data$FFo,predict(gamreg.out))        # RMSE : 2.59
gamreg.out = gam(FFo~ lo(heure)+lo(v)+lo(FFp),family=gaussian,data)
summary(gamreg.out)
source("~/ML-R/TP2/TP2.R", echo=TRUE)
eval(data$FFo,predict(gamreg.out))
